{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apprentissage Supervisé: TP1 - Méthode des K-NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import neighbors\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement du dataset mnist\n",
    "mnist = fetch_openml('mnist_784', return_X_y = True, as_frame = False) \n",
    "data = mnist[0]\n",
    "target = mnist[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On trouve dans $mnist[0]$  la liste des images (tableaux de pixels), et dans $mnist[1]$ la liste des labels correspondants.\n",
    "\n",
    "En d'autres termes, le label correspondant à $mnist[0][n]$ est $mnist[1][n]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 1 : Prise en main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quelques commandes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([[0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       ...,\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.],\n",
      "       [0., 0., 0., ..., 0., 0., 0.]]), array(['5', '0', '4', ..., '4', '5', '6'], dtype=object))\n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "['5' '0' '4' ... '4' '5' '6']\n",
      "Help on built-in function len in module builtins:\n",
      "\n",
      "len(obj, /)\n",
      "    Return the number of items in a container.\n",
      "\n",
      "(70000, 784)\n",
      "(70000,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#N.B: les pixels sont en niveau de gris (valeur entre 0(noir) - 255(blanc))\n",
    "print(mnist)        # Affiche la liste de data et la liste de labels correspondants\n",
    "print(data)         # Affiche la liste de data (tableaux de pixels correspondants aux images)\n",
    "print(target)       # Affiche la liste des labels correspondant aux data \n",
    "len(data)           # Affiche le nombre de données (ici 70 000)\n",
    "help(len)           # Affiche la documentation de la fonction len\n",
    "print(data.shape)   # Affiche le format (longueur, largeur) des data (ici, 70 000 données de 784 pixels chacune)\n",
    "print(target.shape) # Affiche le format des labels (ici, 70 000 labels à la suite)\n",
    "data[0]             # Retourne la liste de pixels associé à la première donnée\n",
    "data[0][1]          # Retourne le deuxième pixel de la première image du dataset \n",
    "data[:,1]           # Retourne le deuxième pixel de chaque image \n",
    "data[:100]          # Retourne les 100 premières images du dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualisation des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe de l'image: 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Transformation des listes de 784 pixels en liste de liste (28x28)\n",
    "images = data.reshape(-1, 28, 28)\n",
    "\n",
    "#Affichage de la première image du dataset\n",
    "plt.imshow(images[0],cmap=plt.cm.gray_r,interpolation=\"nearest\")\n",
    "\n",
    "# Affichage de la classe de l'image correspondante (label)\n",
    "print(f\"Classe de l'image: {target[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercice 2: Méthode des K-NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exercice, nous reprenons le dataset MNIST chargé dans l'exercice 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1ère partie: Classifieur k=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_jobs=-1, n_neighbors=10)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Séléction de 5000 indices aléatoires (entre 0 et 70 000)\n",
    "index = np.random.randint(70000, size=5000)\n",
    "\n",
    "# Attribution des sous-ensembles de data / target\n",
    "sub_data = data[index]\n",
    "sub_target = target[index]\n",
    "\n",
    "# Création du training set (80%) et du testing set (20%)\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(sub_data, sub_target, train_size = 0.8)\n",
    "\n",
    "# Création du classifier avec k = 10\n",
    "k = 10\n",
    "clf = neighbors.KNeighborsClassifier(k, n_jobs=-1)\n",
    "\n",
    "# Entrainement du classifieur\n",
    "clf.fit(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prédiction des images du testing set\n",
    "predictions = clf.predict(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classe prédite: 0\n",
      "Prediction correcte !\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Prédiction de la classe de l'image 4\n",
    "print(f\"Classe prédite: {predictions[4]}\")\n",
    "\n",
    "# Affichage de l'image \n",
    "images_test = xtest.reshape(-1, 28, 28)\n",
    "plt.imshow(images_test[4],cmap=plt.cm.gray_r,interpolation=\"nearest\")\n",
    "\n",
    "if predictions[4] == ytest[4]:\n",
    "    print(\"Prediction correcte !\")\n",
    "else:\n",
    "    print(\"Prediction Incorrecte !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du score sur l'échantillon de test\n",
    "score_test = clf.score(xtest, ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sur l'échantillon de test, on obtient un score de 0.928 (92.80000000000001%) \n"
     ]
    }
   ],
   "source": [
    "# Affichage du score sur l'échantillon de test\n",
    "print(f\"Sur l'échantillon de test, on obtient un score de {score_test} ({score_test*100}%) \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du score sur les données d'apprentissage (pour en déduire le taux d'erreur)\n",
    "score_learning = clf.score(xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score = 0.93725\n",
      "Taux d'erreur = 0.06274999999999997 (0.06274999999999997%)\n"
     ]
    }
   ],
   "source": [
    "# Affichage du score et du taux d'erreur\n",
    "print(f\"Score = {score_learning}\")\n",
    "print(f\"Taux d'erreur = {1 - score_learning} ({1 - score_learning}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On obtient un meilleur score sur le set d' \"entrainement\". Cela est normal car il s'agit du set ayant les voisins étiquettés correctements (car les labels sont connus) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2ème partie: Classifieur avec K variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation du nombre de voisins \n",
    "Ici, nous allons faire varier le nombre de voisins pour trouver le k optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 3\n",
      "score: 0.952\n",
      "k = 5\n",
      "score: 0.948\n",
      "k = 7\n",
      "score: 0.944\n",
      "k = 9\n",
      "score: 0.956\n",
      "k = 11\n",
      "score: 0.948\n",
      "k = 13\n",
      "score: 0.932\n",
      "k = 15\n",
      "score: 0.932\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "# Séléction de n indices aléatoires (entre 0 et 70 000)\n",
    "index = np.random.randint(70000, size=n)\n",
    "\n",
    "# Attribution des sous-ensembles de data / target\n",
    "sub_data = data[index]\n",
    "sub_target = target[index]\n",
    "\n",
    "# Liste des scores obtenues \n",
    "scores = []\n",
    "\n",
    "for k in range(3, 16, 2): # Différents K impairs de 3 à 15\n",
    "    kf = KFold(n_splits=10, shuffle=True) # Séparation de plusieurs set de training et de tests \n",
    "    print(f\"k = {k}\")\n",
    "    scores_fold = [] # Liste des scores obtenues sur chaque split\n",
    "    for train_index, test_index in kf.split(sub_data): \n",
    "        # Affectation des différents sets\n",
    "        xtrain, xtest = sub_data[train_index], sub_data[test_index]\n",
    "        ytrain, ytest = sub_target[train_index], sub_target[test_index]\n",
    "        # Création du classifier\n",
    "        clf = neighbors.KNeighborsClassifier(k, n_jobs=-1)\n",
    "        # Entrainement du classifieur\n",
    "        clf.fit(xtrain, ytrain)\n",
    "        # Calcul du score du classifieur\n",
    "        score = clf.score(xtest, ytest)\n",
    "        scores_fold.append(score)\n",
    "    scores.append((k, max(scores_fold)))\n",
    "    print(f\"score: {scores[-1][1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Le k optimal semble être k = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variation du pourcentage des échantillons de training et testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous faisons varier le pourcentage d'images dans le training et testing set, afin de trouver le meilleur compromis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training: 95.0%\t test: 5%\n",
      "score: 0.908\n",
      "\n",
      "training: 90.0%\t test: 10%\n",
      "score: 0.924\n",
      "\n",
      "training: 85.0%\t test: 15%\n",
      "score: 0.9173333333333333\n",
      "\n",
      "training: 80.0%\t test: 20%\n",
      "score: 0.917\n",
      "\n",
      "training: 75.0%\t test: 25%\n",
      "score: 0.9144\n",
      "\n",
      "training: 70.0%\t test: 30%\n",
      "score: 0.9206666666666666\n",
      "\n",
      "training: 65.0%\t test: 35%\n",
      "score: 0.9102857142857143\n",
      "\n",
      "training: 60.0%\t test: 40%\n",
      "score: 0.9105\n",
      "\n",
      "training: 55.00000000000001%\t test: 45%\n",
      "score: 0.9102222222222223\n",
      "\n",
      "training: 50.0%\t test: 50%\n",
      "score: 0.9056\n",
      "\n",
      "training: 45.0%\t test: 55%\n",
      "score: 0.904\n",
      "\n",
      "training: 40.0%\t test: 60%\n",
      "score: 0.904\n",
      "\n",
      "training: 35.0%\t test: 65%\n",
      "score: 0.8901538461538462\n",
      "\n",
      "training: 30.0%\t test: 70%\n",
      "score: 0.8848571428571429\n",
      "\n",
      "training: 25.0%\t test: 75%\n",
      "score: 0.8736\n",
      "\n",
      "training: 20.0%\t test: 80%\n",
      "score: 0.86275\n",
      "\n",
      "training: 15.0%\t test: 85%\n",
      "score: 0.8510588235294118\n",
      "\n",
      "training: 10.0%\t test: 90%\n",
      "score: 0.8168888888888889\n",
      "\n",
      "training: 5.0%\t test: 95%\n",
      "score: 0.7256842105263158\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "# Séléction de n indices aléatoires (entre 0 et 70 000)\n",
    "index = np.random.randint(70000, size=n)\n",
    "\n",
    "# Attribution des sous-ensembles de data / target\n",
    "sub_data = data[index]\n",
    "sub_target = target[index]\n",
    "\n",
    "k = 9\n",
    "for test_percentage in range(5, 100, 5): # Différents K impairs de 3 à 15\n",
    "    train_percentage = (100 - test_percentage) / 100\n",
    "    print(f\"training: {train_percentage*100}%\\t test: {test_percentage}%\")\n",
    "    # Affectation des différents sets\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(sub_data, sub_target, train_size = train_percentage)\n",
    "    # Création du classifier\n",
    "    clf = neighbors.KNeighborsClassifier(k, n_jobs=-1)\n",
    "    # Entrainement du classifieur\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    # Calcul du score du classifieur\n",
    "    score = clf.score(xtest, ytest)\n",
    "    print(f\"score: {score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque qu'avec trop de données d'entrainement, on perd en précision de prédiction (95%)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous faisons maintenant varier le paramètre p du classifieur, afin de calculer la distance entre les données en utilisant la distance Euclidienne (p=2), la distance de Manhattan (p=1), ou bien la distance de Minkowski (p>2)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p: 1\n",
      "score: 0.895\n",
      "\n",
      "p: 2\n",
      "score: 0.921\n",
      "\n",
      "p: 3\n",
      "score: 0.923\n",
      "\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "# Séléction de n indices aléatoires (entre 0 et 70 000)\n",
    "index = np.random.randint(70000, size=n)\n",
    "\n",
    "# Attribution des sous-ensembles de data / target\n",
    "sub_data = data[index]\n",
    "sub_target = target[index]\n",
    "\n",
    "k = 9\n",
    "for p in range(1, 4): # Différents paramètres p\n",
    "    print(f\"p: {p}\")\n",
    "    # Affectation des différents sets\n",
    "    xtrain, xtest, ytrain, ytest = train_test_split(sub_data, sub_target, train_size = 0.8)\n",
    "    # Création du classifier\n",
    "    clf = neighbors.KNeighborsClassifier(k, n_jobs=-1, p=p)\n",
    "    # Entrainement du classifieur\n",
    "    clf.fit(xtrain, ytrain)\n",
    "    # Calcul du score du classifieur\n",
    "    score = clf.score(xtest, ytest)\n",
    "    print(f\"score: {score}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les meilleures distances semblent être les distances Eclidienne et de Minkowski"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons maintenant mesurer le temps d'éxecution de l'entrainement et du calcul du score, en utilisant 1 coeur (n_jobs=1), puis tous les coeurs (n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution avec 1 Coeur\n",
      "Temps d'éxecution: 3.695591449737549\n",
      "Execution avec tous les coeurs\n",
      "Temps d'éxecution: 0.5804717540740967\n"
     ]
    }
   ],
   "source": [
    "n = 5000\n",
    "# Séléction de n indices aléatoires (entre 0 et 70 000)\n",
    "index = np.random.randint(70000, size=n)\n",
    "\n",
    "# Attribution des sous-ensembles de data / target\n",
    "sub_data = data[index]\n",
    "sub_target = target[index]\n",
    "\n",
    "k=9\n",
    "p=2\n",
    "train_size=0.8\n",
    "\n",
    "# 1 coeur\n",
    "print(\"Execution avec 1 Coeur\")\n",
    "\n",
    "start_time = time.time()\n",
    "# Affectation des différents sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(sub_data, sub_target, train_size = train_size)\n",
    "# Création du classifier\n",
    "clf = neighbors.KNeighborsClassifier(k, n_jobs=1, p=p)\n",
    "# Entrainement du classifieur\n",
    "clf.fit(xtrain, ytrain)\n",
    "# Calcul du score du classifieur\n",
    "score = clf.score(xtest, ytest)\n",
    "\n",
    "print(f\"Temps d'éxecution: {time.time() - start_time}\")\n",
    "\n",
    "\n",
    "# Tous les coeur\n",
    "print(\"Execution avec tous les coeurs\")\n",
    "start_time = time.time()\n",
    "# Affectation des différents sets\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(sub_data, sub_target, train_size = train_size)\n",
    "# Création du classifier\n",
    "clf = neighbors.KNeighborsClassifier(k, n_jobs=-1, p=p)\n",
    "# Entrainement du classifieur\n",
    "clf.fit(xtrain, ytrain)\n",
    "# Calcul du score du classifieur\n",
    "score = clf.score(xtest, ytest)\n",
    "\n",
    "print(f\"Temps d'éxecution: {time.time() - start_time}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On remarque que le temps d'éxecution obtenu en parallelisant la création du classifier et le calcul du score est nettement plus court (~ 7x plus rapide). Cela veut dire que la méthode est parallelisable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Avantages et Inconvénients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avantages:\n",
    "* L'algorithme se comprend facilement\n",
    "* Il suffit de de savoir placer une donnée pour l'utiliser (pas de biais à appliquer)\n",
    "* Sur l'exemple de MNIST, l'algoritme offre de très bon résultats (~90% de reconnaissance)\n",
    "\n",
    "Inconvénients:\n",
    "* La durée des prédictions est directement liée au nombre de données, ce qui complique le passage à l'echelle\n",
    "* L'algorithme ne peut pas être utilisé si des prédictions rapides sont necessaires. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
